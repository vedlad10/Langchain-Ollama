# Langchain-Ollama
This project demonstrates how to build a lightweight AI assistant using LangChainâ€™s LCEL pipeline and a locally hosted large language model via Ollama. The application provides a simple web interface built with Streamlit, allowing users to ask questions and receive real-time responses without relying on paid cloud APIs.
